{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb2df095",
   "metadata": {},
   "source": [
    "# 2023_08_24\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c011d91",
   "metadata": {},
   "source": [
    "### regression\n",
    "\n",
    "현재 regression을 모델을 이용해서 연어의 중량 측정하는 모델을 만들었다.  \n",
    "사용하는 모델은 `linear regression` , `ploy_regression` , `decision_tree` , `random forest` 4개의 모델으 사용함  \n",
    "\n",
    "* fix regression\n",
    "\n",
    "일반적인 regression의 경우에는 변수를 사용하면 할 수록 예측을 잘해서 error가 낮아져야 하는데 지금 결과를 그렇지 않음  \n",
    "이를 확인해서 고칠 필요가 있음  \n",
    "\n",
    "* LightGBM\n",
    "현재 사업 계획서 상에서 사용하는 모델인 LightGBM에 대해서 test에 대한 NRMSE를 계산하는 plot도 추가가 필요함  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2be9e",
   "metadata": {},
   "source": [
    "* fix regression\n",
    "\n",
    "> http://202.31.200.194:8888/notebooks/NPLAB-NAS/Members/SEO/salom_ai/regression/fish_weight_regression.ipynb#nrmse-%EA%B3%84%EC%82%B0-%EB%B0%8F-%EC%8B%9C%EA%B0%81%ED%99%94\n",
    "\n",
    "corr을 확인해본 결과 \n",
    "corr이 높아서 다중공산성의 문제가 발생한 듯함  \n",
    "아래 table을 각 변수별로 regression의 결과인데  \n",
    "예상처럼 nrmse가 줄어드는 경우도 있지만 대부분이 줄어들지 않음  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0e8e98",
   "metadata": {},
   "source": [
    "<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>Variables</th>      <th>linear_regression_NRMSE</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>SL</td>      <td>0.154105</td>    </tr>    <tr>      <th>1</th>      <td>FL</td>      <td>0.142477</td>    </tr>    <tr>      <th>2</th>      <td>TL</td>      <td>0.138350</td>    </tr>    <tr>      <th>3</th>      <td>BD</td>      <td>0.076932</td>    </tr>    <tr>      <th>4</th>      <td>BT</td>      <td>0.072074</td>    </tr>    <tr>      <th>5</th>      <td>(\\'SL\\', \\'FL\\')</td>      <td>0.132207</td>    </tr>    <tr>      <th>6</th>      <td>(\\'SL\\', \\'TL\\')</td>      <td>0.132316</td>    </tr>    <tr>      <th>7</th>      <td>(\\'SL\\', \\'BD\\')</td>      <td>0.079082</td>    </tr>    <tr>      <th>8</th>      <td>(\\'SL\\', \\'BT\\')</td>      <td>0.114035</td>    </tr>    <tr>      <th>9</th>      <td>(\\'FL\\', \\'TL\\')</td>      <td>0.145082</td>    </tr>    <tr>      <th>10</th>      <td>(\\'FL\\', \\'BD\\')</td>      <td>0.082370</td>    </tr>    <tr>      <th>11</th>      <td>(\\'FL\\', \\'BT\\')</td>      <td>0.116226</td>    </tr>    <tr>      <th>12</th>      <td>(\\'TL\\', \\'BD\\')</td>      <td>0.080129</td>    </tr>    <tr>      <th>13</th>      <td>(\\'TL\\', \\'BT\\')</td>      <td>0.113961</td>    </tr>    <tr>      <th>14</th>      <td>(\\'BD\\', \\'BT\\')</td>      <td>0.062440</td>    </tr>    <tr>      <th>15</th>      <td>(\\'SL\\', \\'FL\\', \\'TL\\')</td>      <td>0.135658</td>    </tr>    <tr>      <th>16</th>      <td>(\\'SL\\', \\'FL\\', \\'BD\\')</td>      <td>0.084905</td>    </tr>    <tr>      <th>17</th>      <td>(\\'SL\\', \\'FL\\', \\'BT\\')</td>      <td>0.119876</td>    </tr>    <tr>      <th>18</th>      <td>(\\'SL\\', \\'TL\\', \\'BD\\')</td>      <td>0.080100</td>    </tr>    <tr>      <th>19</th>      <td>(\\'SL\\', \\'TL\\', \\'BT\\')</td>      <td>0.113750</td>    </tr>    <tr>      <th>20</th>      <td>(\\'SL\\', \\'BD\\', \\'BT\\')</td>      <td>0.070811</td>    </tr>    <tr>      <th>21</th>      <td>(\\'FL\\', \\'TL\\', \\'BD\\')</td>      <td>0.088716</td>    </tr>    <tr>      <th>22</th>      <td>(\\'FL\\', \\'TL\\', \\'BT\\')</td>      <td>0.124388</td>    </tr>    <tr>      <th>23</th>      <td>(\\'FL\\', \\'BD\\', \\'BT\\')</td>      <td>0.076000</td>    </tr>    <tr>      <th>24</th>      <td>(\\'TL\\', \\'BD\\', \\'BT\\')</td>      <td>0.073919</td>    </tr>    <tr>      <th>25</th>      <td>(\\'SL\\', \\'FL\\', \\'TL\\', \\'BD\\')</td>      <td>0.092046</td>    </tr>    <tr>      <th>26</th>      <td>(\\'SL\\', \\'FL\\', \\'TL\\', \\'BT\\')</td>      <td>0.125461</td>    </tr>    <tr>      <th>27</th>      <td>(\\'SL\\', \\'FL\\', \\'BD\\', \\'BT\\')</td>      <td>0.082119</td>    </tr>    <tr>      <th>28</th>      <td>(\\'SL\\', \\'TL\\', \\'BD\\', \\'BT\\')</td>      <td>0.070061</td>    </tr>    <tr>      <th>29</th>      <td>(\\'FL\\', \\'TL\\', \\'BD\\', \\'BT\\')</td>      <td>0.083992</td>    </tr>    <tr>      <th>30</th>      <td>(\\'SL\\', \\'FL\\', \\'TL\\', \\'BD\\', \\'BT\\')</td>      <td>0.086676</td>    </tr>  </tbody></table>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af879fc",
   "metadata": {},
   "source": [
    "* lightGBM\n",
    "\n",
    "> http://202.31.200.194:8888/notebooks/NPLAB-NAS/Members/SEO/salom_ai/regression/fish_weight_regression.ipynb#light-gbm\n",
    "현재 155개의 row가 있고 lightGBM을 돌려보니 데이터가 작아서 학습이 잘 되지 않음  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc73312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
