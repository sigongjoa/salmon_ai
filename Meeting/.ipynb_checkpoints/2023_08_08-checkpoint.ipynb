{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b7fad4",
   "metadata": {},
   "source": [
    "# 2023_08_08\n",
    "\n",
    "\n",
    "### binary cross entropy\n",
    "\n",
    "현재 예측값이 pretrained 모델의 레이블 정보를 가지고 있어서 여러 개의 label이 나타남  \n",
    "이를 loss function을 binary cross entropy로 변경해서 학습 진행  \n",
    "\n",
    "> https://discuss.huggingface.co/t/binary-semantic-segmentation-using-segformer/25745/7\n",
    "\n",
    "### Feature Extractor\n",
    "\n",
    "현재 SegformerFeatureExtractor를 사용하는 이게 실제 연어 데이터에 대해서 색상을 부각시키고 배경을 없앰  \n",
    "이를 확인해서 정상적으로 학습되도록 만듬  \n",
    "\n",
    "### image size\n",
    "현재 image 사이즈가 작아서 학습이 제대로 안되는 부분이 있음  \n",
    "이를 SegformerFeatureExtractor를 현재 256 * 256 크기의 이미지를 512 * 512 혹은 1024 * 1024 이미지에서 학습 진행  \n",
    "\n",
    "### change iou\n",
    "현재 iou를 foreground(fish)에 대해서만 계산을 함  \n",
    "이를 background와 foregournd에 대해서도 계산을 하도록 변경하고  \n",
    "학습시에도 tensorboard에 background와 foregroud에 대해서 기록 되도록 변경   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7c0a16",
   "metadata": {},
   "source": [
    "### binary cross entropy\n",
    "\n",
    "기본적으로 loss는 BCEWITHLOGITSLOSS를 사용함  \n",
    "loss를 바꾸는 코드가 없어서 classifier를 binary로 바꿈  \n",
    "\n",
    "> loss : https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html\n",
    "\n",
    "> https://discuss.huggingface.co/t/binary-semantic-segmentation-using-segformer/25745/7\n",
    "\n",
    "\n",
    "model config를 pretrained model config를 사용하고 있었음  \n",
    "\n",
    "> result : http://202.31.200.123:8888/notebooks/NPLAB-NAS/Members/SEO/salom_ai/infernce.ipynb#2023_08_04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa17f038",
   "metadata": {},
   "source": [
    "### b5 model\n",
    "\n",
    "> https://huggingface.co/docs/transformers/main/model_doc/segformer\n",
    "\n",
    "hugging face의 공식 홈페이지에서는 다음과 같은 pre-trained 모델을 사용이 가능함  \n",
    "\n",
    "| Model variant | Depths        | Hidden sizes        | Decoder hidden size | Params (M) | ImageNet-1k Top 1 |\n",
    "|---------------|---------------|---------------------|---------------------|------------|-------------------|\n",
    "| MiT-b0        | [2, 2, 2, 2]  | [32, 64, 160, 256]  | 256                 | 3.7        | 70.5              |\n",
    "| MiT-b1        | [2, 2, 2, 2]  | [64, 128, 320, 512] | 256                 | 14.0       | 78.7              |\n",
    "| MiT-b2        | [3, 4, 6, 3]  | [64, 128, 320, 512] | 768                 | 25.4       | 81.6              |\n",
    "| MiT-b3        | [3, 4, 18, 3] | [64, 128, 320, 512] | 768                 | 45.2       | 83.1              |\n",
    "| MiT-b4        | [3, 8, 27, 3] | [64, 128, 320, 512] | 768                 | 62.6       | 83.6              |\n",
    "| MiT-b5        | [3, 6, 40, 3] | [64, 128, 320, 512] | 768                 | 82.0       | 83.8              |\n",
    "\n",
    "실제로 사용을 해봤을 때 MiT-b5 모델은 사용이 불가능 했음  \n",
    "\n",
    "\n",
    "hugging face의 Model에서 `nvidia/segformer-b5-finetuned-cityscapes-1024-1024` 다음 모델을 사용함   \n",
    "\n",
    "> https://huggingface.co/models?search=segformer_b5\n",
    "\n",
    "다른 모델을 사용이 가능하나 우선은 확인 용도로 위 모델을 사용  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983b525d",
   "metadata": {},
   "source": [
    "### Feature Extractor\n",
    "\n",
    "> https://huggingface.co/docs/transformers/main/model_doc/segformer#transformers.SegformerImageProcessor\n",
    "\n",
    "| 옵션명 | 설명 |\n",
    "|--|--|\n",
    "| do_resize | 이미지의 (높이, 너비) 차원을 지정된 크기로 조정할지 여부 |\n",
    "| size | 크기 조정 후 출력 이미지의 크기 |\n",
    "| resample | 이미지 크기를 조정할 때 사용할 리샘플링 필터 |\n",
    "| do_rescale | 지정된 스케일로 이미지를 재조정할지 여부 |\n",
    "| rescale_factor | 이미지를 정규화할지 여부 |\n",
    "| do_normalize | 이미지를 정규화할지 여부 |\n",
    "| image_mean | 이미지를 정규화할 때 사용할 평균 |\n",
    "| image_std | 이미지를 정규화할 때 사용할 표준 편차 |\n",
    "| do_reduce_labels | 세그멘테이션 맵의 모든 레이블 값을 1만큼 줄일지 여부 |\n",
    "\n",
    "\n",
    "다음과 같은 옵션을 선택을 해서 셋팅이 가능함  \n",
    "\n",
    "> http://202.31.200.123:8888/notebooks/NPLAB-NAS/Members/SEO/salom_ai/dataloader_check.ipynb#2023_08_08\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66680f71",
   "metadata": {},
   "source": [
    "### change iou\n",
    "\n",
    "test loop가 끝날때 각 category 별로 iou 를 metric으로 넘김  \n",
    "tensorborad에도 각 background와 foreground에 대해서도 log를 남기도록 수정  \n",
    "\n",
    "\n",
    "``` python\n",
    "class SegformerFinetuner(pl.LightningModule):    \n",
    "    def __init__(self, id2label, pre_trained ,  train_dataloader=None, val_dataloader=None, test_dataloader=None, metrics_interval=100):\n",
    "        super(SegformerFinetuner, self).__init__()\n",
    "        print(f\"pre_trained_mode : {pre_trained}\")\n",
    "        self.id2label = id2label\n",
    "        self.metrics_interval = metrics_interval\n",
    "        self.train_dl = train_dataloader\n",
    "        self.val_dl = val_dataloader\n",
    "        self.test_dl = test_dataloader\n",
    "        \n",
    "        self.num_classes = len(id2label.keys())\n",
    "        self.label2id = {v:k for k,v in self.id2label.items()}\n",
    "        \n",
    "        \n",
    "        print(self.id2label)\n",
    "        print(self.label2id)\n",
    "        \n",
    "        self.model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            pre_trained, \n",
    "            return_dict=False, \n",
    "            num_labels=self.num_classes,\n",
    "            id2label=self.id2label,\n",
    "            label2id=self.label2id,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.train_mean_iou = load_metric(\"mean_iou\")\n",
    "        self.val_mean_iou = load_metric(\"mean_iou\")\n",
    "        self.test_mean_iou = load_metric(\"mean_iou\")\n",
    "                \n",
    "    def forward(self, images, masks):\n",
    "        outputs = self.model(pixel_values=images, labels=masks)\n",
    "        return(outputs)\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        outputs = self(images, masks)\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits, \n",
    "            size=masks.shape[-2:], \n",
    "            mode=\"bilinear\", \n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "        self.train_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(), \n",
    "            references=masks.detach().cpu().numpy()\n",
    "        )\n",
    "        \n",
    "        if batch_nb % self.metrics_interval == 0:\n",
    "\n",
    "            metrics = self.train_mean_iou.compute(\n",
    "                num_labels=self.num_classes, \n",
    "                ignore_index=255, \n",
    "                reduce_labels=False,\n",
    "            )\n",
    "            \n",
    "            metrics = {'loss': loss, \"mean_iou\": metrics[\"mean_iou\"], \"mean_accuracy\": metrics[\"mean_accuracy\"]}\n",
    "            \n",
    "            \n",
    "            for k,v in metrics.items():\n",
    "                self.log(k,v)\n",
    "            \n",
    "            return(metrics)\n",
    "        else:\n",
    "            return({'loss': loss})\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        outputs = self(images, masks)\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits, \n",
    "            size=masks.shape[-2:], \n",
    "            mode=\"bilinear\", \n",
    "            align_corners=False\n",
    "        )\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "        self.val_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(), \n",
    "            references=masks.detach().cpu().numpy()\n",
    "        )\n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.val_mean_iou.compute(\n",
    "            num_labels=self.num_classes, \n",
    "            ignore_index=255, \n",
    "            reduce_labels=False,\n",
    "        )\n",
    "        \n",
    "        ### add code ###\n",
    "        val_mean_iou = metrics[\"mean_iou\"]\n",
    "        val_mean_accuracy = metrics[\"mean_accuracy\"]\n",
    "        val_background_iou = metrics['per_category_iou'][0]\n",
    "        val_foreground_iou = metrics['per_category_iou'][1]\n",
    "        \n",
    "        self.log(\"val_mean_iou\", val_mean_iou, prog_bar=True, logger=True)\n",
    "        self.log(\"val_background_iou\", val_background_iou, prog_bar=True, logger=True)\n",
    "        self.log(\"val_foreground_iou\", val_foreground_iou, prog_bar=True, logger=True)\n",
    "        self.log(\"val_mean_accuracy\", val_mean_accuracy, prog_bar=True, logger=True)\n",
    "        ################\n",
    "    \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        \n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        outputs = self(images, masks)\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits, \n",
    "            size=masks.shape[-2:], \n",
    "            mode=\"bilinear\", \n",
    "            align_corners=False\n",
    "        )\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "        self.test_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(), \n",
    "            references=masks.detach().cpu().numpy()\n",
    "        )\n",
    "        return({'test_loss': loss})\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        metrics = self.test_mean_iou.compute(\n",
    "              num_labels=self.num_classes, \n",
    "              ignore_index=255, \n",
    "              reduce_labels=False,\n",
    "          )\n",
    "        avg_test_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean()\n",
    "        test_mean_iou = metrics[\"mean_iou\"]\n",
    "        test_mean_accuracy = metrics[\"mean_accuracy\"]\n",
    "        \n",
    "        ### add code ###\n",
    "        metrics = {\"test_loss\": avg_test_loss, \n",
    "                   \"test_mean_iou\":test_mean_iou, \n",
    "                   \"test_mean_accuracy\":test_mean_accuracy,\n",
    "                   \"backgournd_iou\" : metrics['per_category_iou'][0] , \n",
    "                   \"foregournd_iou\" : metrics['per_category_iou'][1]\n",
    "                   }\n",
    "        ################\n",
    "        for k,v in metrics.items():\n",
    "            self.log(k,v)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=2e-05, eps=1e-08)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.train_dl\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return self.val_dl\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return self.test_dl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5678025b",
   "metadata": {},
   "source": [
    "### change iou\n",
    "\n",
    "miou 계산 방식을 hugging face의 `load_metric('mean_iou')`로 변경해서 확인\n",
    "\n",
    "``` python \n",
    "results = load_metric('mean_iou').compute(predictions=[predicted[i]], \n",
    "                                      references=[batch['labels'][i]], \n",
    "                                      num_labels=2, \n",
    "                                      ignore_index=255)\n",
    "```\n",
    "\n",
    "> infernce notebook : http://202.31.200.123:8888/notebooks/NPLAB-NAS/Members/SEO/salom_ai/infernce.ipynb#2023_08_08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b7c1ee",
   "metadata": {},
   "source": [
    "### normalize off\n",
    "\n",
    "normalize의 옵션을 끄고 학습을 하고 추론\n",
    "\n",
    "> tensorboard : http://202.31.200.70:8888/notebooks/NPLAB-NAS/Members/SEO/salom_ai/tensorboard.ipynb\n",
    "\n",
    "> infercne : http://202.31.200.194:8888/notebooks/NPLAB-NAS/Members/SEO/salom_ai/infernce.ipynb#2023_08_09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadbfa34",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "\n",
    "학습용 데이터가 310장 정도여서 데이터가 부족한것 같아서 다음과 같은 데이터 증강을 이용해서 데이터를 더 확보를 진행  \n",
    "\n",
    "> transform test : http://202.31.200.194:8888/notebooks/NPLAB-NAS/Members/SEO/salom_ai/dataloader_check.ipynb#transform-check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c265474",
   "metadata": {},
   "source": [
    "### DeepFish network\n",
    "\n",
    "* haven-ai install : pip install --upgrade git+https://github.com/haven-ai/haven-ai\n",
    "\n",
    "> dataloader visualization : http://202.31.200.194:8888/notebooks/NPLAB-NAS/Members/SEO/salom_ai/DeepFish/scripts/training.ipynb#visualize-dataset\n",
    "\n",
    "> training : http://202.31.200.194:8888/notebooks/NPLAB-NAS/Members/SEO/salom_ai/DeepFish/scripts/training.ipynb#training\n",
    "\n",
    "> infrecne : http://202.31.200.194:8888/notebooks/NPLAB-NAS/Members/SEO/salom_ai/DeepFish/scripts/training.ipynb#model-load-&-infrernce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013c5bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
